{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ee448e-042c-44bd-949d-b43a268594a8",
   "metadata": {},
   "source": [
    "### Test on Small Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b50a236-07e4-4b0c-b23a-b91fd2b5abcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gymnasium\n",
      "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\rohan mehra\\anaconda3\\lib\\site-packages (from gymnasium) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\rohan mehra\\anaconda3\\lib\\site-packages (from gymnasium) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\rohan mehra\\anaconda3\\lib\\site-packages (from gymnasium) (4.12.2)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\rohan mehra\\anaconda3\\lib\\site-packages (from gymnasium) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\rohan mehra\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.7.0)\n",
      "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
      "   ---------------------------------------- 958.1/958.1 kB 6.1 MB/s eta 0:00:00\n",
      "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: farama-notifications, gymnasium\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca022ddd-53e3-4b4e-a6f5-04662a35eb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Score = 75.60000000000001\n",
      "Episode 2: Total Score = 167.40000000000006\n",
      "Episode 3: Total Score = 90.60000000000001\n",
      "Episode 4: Total Score = 114.00000000000003\n",
      "Episode 5: Total Score = 90.60000000000002\n",
      "Episode 6: Total Score = 61.80000000000001\n",
      "Episode 7: Total Score = 105.60000000000002\n",
      "Episode 8: Total Score = 85.20000000000002\n",
      "Episode 9: Total Score = 109.80000000000001\n",
      "Episode 10: Total Score = 109.80000000000001\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import rware\n",
    "from rware.warehouse import RewardType\n",
    "import torch as T\n",
    "from dql import DQNAgent, DeepQNetwork\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def load_agents(n_agents, save_dir='saved_models'):\n",
    "    \"\"\"Load trained agents from disk\"\"\"\n",
    "    agents = []\n",
    "    \n",
    "    for i in range(n_agents):\n",
    "        \n",
    "        # Create agent with loaded parameters\n",
    "        agent = DQNAgent(\n",
    "            gamma=0.95,\n",
    "            epsilon=0.25,  # Use minimum epsilon for testing\n",
    "            lr=0.001,\n",
    "            input_dims=(71,),\n",
    "            batch_size=64,\n",
    "            n_actions=5,\n",
    "            max_mem_size=100000\n",
    "        )\n",
    "        \n",
    "        # Load network weights\n",
    "        agent.Q_eval.load_state_dict(T.load(f'{save_dir}/agentsmall_{i}_Q_eval.pth'))\n",
    "        \n",
    "        agents.append(agent)\n",
    "    \n",
    "    return agents\n",
    "\n",
    "def test_agents(n_episodes=10, max_steps=1000):\n",
    "    layout = \"\"\"\n",
    "    ......\n",
    "    ..xx..\n",
    "    ..xx..\n",
    "    ..xx..\n",
    "    ......\n",
    "    ..gg..\n",
    "    \"\"\"\n",
    "\n",
    "    # layout = \"\"\"\n",
    "    # ......\n",
    "    # ..xx..\n",
    "    # ..xx..\n",
    "    # ..xx..\n",
    "    # ..xx..\n",
    "    # ..xx..\n",
    "    # ..xx..\n",
    "    # ..xx..\n",
    "    # ......\n",
    "    # ..gg..\n",
    "    # \"\"\"\n",
    "    env = gym.make(\"rware-tiny-2ag-v2\",layout=layout, reward_type=RewardType.TWO_STAGE)\n",
    "    n_agents = 2\n",
    "    \n",
    "    # Load trained agents\n",
    "    agents = load_agents(n_agents)\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        observations = env.reset()[0]\n",
    "        episode_scores = [0] * n_agents\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            # Get actions from trained agents\n",
    "            actions = [agent.choose_action(observations[agent_id]) for agent_id, agent in enumerate(agents)]\n",
    "            observations_, rewards, dones, _, _ = env.step(tuple(actions))\n",
    "            env.render()\n",
    "            \n",
    "            rewards = list(rewards)\n",
    "            \n",
    "            # Update episode scores\n",
    "            for agent_id in range(n_agents):\n",
    "                if round(rewards[agent_id], 1) != -0.6 and round(rewards[agent_id], 1) != -0.3:\n",
    "                    episode_scores[agent_id] += rewards[agent_id]\n",
    "            \n",
    "            observations = observations_\n",
    "            time.sleep(0.004)\n",
    "        \n",
    "        total_score = sum(episode_scores)\n",
    "        print(f\"Episode {episode + 1}: Total Score = {total_score}\")\n",
    "    \n",
    "    env.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd9bf85-9668-439f-9ae8-93060e1bc238",
   "metadata": {},
   "source": [
    "### Test on Large Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd39597-824d-40a9-b31c-012d21d543c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Score = 42.60000000000001\n",
      "Episode 2: Total Score = 28.800000000000004\n",
      "Episode 3: Total Score = 52.2\n",
      "Episode 4: Total Score = 37.2\n",
      "Episode 5: Total Score = 52.2\n",
      "Episode 6: Total Score = 96.00000000000001\n",
      "Episode 7: Total Score = 27.6\n",
      "Episode 8: Total Score = 57.60000000000001\n",
      "Episode 9: Total Score = 79.80000000000001\n",
      "Episode 10: Total Score = 42.60000000000001\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import rware\n",
    "from rware.warehouse import RewardType\n",
    "import torch as T\n",
    "from dql import DQNAgent, DeepQNetwork\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def load_agents(n_agents, save_dir='saved_models'):\n",
    "    \"\"\"Load trained agents from disk\"\"\"\n",
    "    agents = []\n",
    "    \n",
    "    for i in range(n_agents):\n",
    "        \n",
    "        # Create agent with loaded parameters\n",
    "        agent = DQNAgent(\n",
    "            gamma=0.95,\n",
    "            epsilon=0.37,  # Use minimum epsilon for testing\n",
    "            lr=0.001,\n",
    "            input_dims=(71,),\n",
    "            batch_size=64,\n",
    "            n_actions=5,\n",
    "            max_mem_size=100000\n",
    "        )\n",
    "        \n",
    "        # Load network weights\n",
    "        agent.Q_eval.load_state_dict(T.load(f'{save_dir}/agentlarge_{i}_Q_eval.pth'))\n",
    "        \n",
    "        agents.append(agent)\n",
    "    \n",
    "    return agents\n",
    "\n",
    "def test_agents(n_episodes=10, max_steps=1000):\n",
    "    # layout = \"\"\"\n",
    "    # ......\n",
    "    # ..xx..\n",
    "    # ..xx..\n",
    "    # ..xx..\n",
    "    # ......\n",
    "    # ..gg..\n",
    "    # \"\"\"\n",
    "\n",
    "    layout = \"\"\"\n",
    "    ......\n",
    "    ..xx..\n",
    "    ..xx..\n",
    "    ..xx..\n",
    "    ..xx..\n",
    "    ..xx..\n",
    "    ..xx..\n",
    "    ..xx..\n",
    "    ......\n",
    "    ..gg..\n",
    "    \"\"\"\n",
    "    env = gym.make(\"rware-tiny-2ag-v2\",layout=layout, reward_type=RewardType.TWO_STAGE)\n",
    "    n_agents = 2\n",
    "    \n",
    "    # Load trained agents\n",
    "    agents = load_agents(n_agents)\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        observations = env.reset()[0]\n",
    "        episode_scores = [0] * n_agents\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            # Get actions from trained agents\n",
    "            actions = [agent.choose_action(observations[agent_id]) for agent_id, agent in enumerate(agents)]\n",
    "            observations_, rewards, dones, _, _ = env.step(tuple(actions))\n",
    "            env.render()\n",
    "            \n",
    "            rewards = list(rewards)\n",
    "            \n",
    "            # Update episode scores\n",
    "            for agent_id in range(n_agents):\n",
    "                if round(rewards[agent_id], 1) != -0.6 and round(rewards[agent_id], 1) != -0.3:\n",
    "                    episode_scores[agent_id] += rewards[agent_id]\n",
    "            \n",
    "            observations = observations_\n",
    "            time.sleep(0.002)\n",
    "        \n",
    "        total_score = sum(episode_scores)\n",
    "        print(f\"Episode {episode + 1}: Total Score = {total_score}\")\n",
    "    \n",
    "    env.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_agents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef1e1b-10c0-45d3-baf1-cf7341416f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61bba39-eb08-46c9-9aed-cde0cf54cb11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
